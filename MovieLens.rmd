---
title: "**HarvardX Data Science Professional Certificate  \n  PH125.9x Capstone 1 - MovieLens Recommendation System**"
author: "_Hugo Aquino_"
date: "_`r Sys.Date()`_"
urlcolor: blue
geometry: margin=0.57in
output:
  rmarkdown::pdf_document:
    toc: true
    toc_depth: 4
    number_sections: yes
    fig_caption: yes
    highlight: tango
    keep_tex: yes
    includes:
      in_header: header.tex
header-includes:
  - \usepackage{titling}
  - \usepackage{fancyhdr}
  - \pretitle{\begin{center}
    \includegraphics[width=3in,height=3in]{edx_logo.png}\LARGE\\}
  - \posttitle{\end{center}}

include-before: '`\newpage{}`{=latex}'
---

`\newpage{}`{=latex}'

\addtolength{\headheight}{0.35cm} 
\pagestyle{fancyplain} 
\lhead{\includegraphics[height=1cm]{edx_logo.png}} 
\rhead{\includegraphics[height=1.5cm]{hardvard_x.jpeg}} 
\renewcommand{\headrulewidth}{0pt}

# Introduction 

**Data** is the _new fuel_ of this era in which many situations can be tracked using records that came from several sources. These data need to be cleaned and organized in a way that with the support of tools such as **R** and new techniques, the data can talk to show patterns and relationships that allow us to anticipate and therefore take better decisions.

**Data Science** is emerging as one of the most important knowledge areas and the **data scientists** are becoming one of the best jobs paid, this role combines computing/programming skills with statistics to analyze raw data and transforming it for its use on an industry.

Companies such as [Netflix][netflix], [Amazon][amazon], [Spotify][spotify] among others use a [recommendation system][recommendation_system] (kind of system used to recommend things based on several factors) as a way to identify the adequate product and these companies are accelerating its value proposition and increasing its market share through the use of machine learning and artificial intelligence algorithms.

Therefore and as a way to continue acquiring the skills needed to become a data scientist, this project will be focused on the creation of a recommendation system using the [10M version of the MovieLens dataset][movielens] through the segmentation on **train** and **validation** sets using different algorithms.

In order to compare the different algorithms, the **root mean squared error (RMSE)** will be used as the loss function, so the target is to obtain a RMSE lower than **0.86490**.

The files required for this project ([pdf][pdf_file], [rmd][rmd_file], [R][r_file]) are hosted on [github][github].

`\newpage{}`{=latex}'

# Methods

## Libraries

The libraries used for this project are:

```{r loading-libraries, warning = FALSE, message = FALSE}

# Install libraries with its dependencies 
if(!require(tidyverse)) install.packages(
  "tidyverse", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(caret)) install.packages(
  "caret", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(data.table)) install.packages(
"data.table", 
repos = "http://cran.us.r-project.org", 
dependencies = TRUE)
if(!require(ggplot2)) install.packages(
  "ggplot2", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(ggthemes)) install.packages(
  "ggthemes", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(lubridate)) install.packages(
  "lubridate", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(corrplot)) install.packages(
  "corrplot", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(recosystem)) install.packages(
  "recosystem", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(knitr)) install.packages(
  "knitr", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(kableExtra)) install.packages(
  "kableExtra", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(tinytex)) install.packages(
  "tinytex", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(scales)) install.packages(
  "scales", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(tidyr)) install.packages(
  "tidyr", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(lubridate)) install.packages(
  "lubridate", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(stringr)) install.packages(
  "stringr", 
  repos = "http://cran.us.r-project.org", 
  dependencies = TRUE)
if(!require(corrplot)) install.packages(
  "corrplot", 
  repos = "http://cran.us.r-project.org",
  dependencies = TRUE)
if(!require(recosystem)) install.packages(
  "recosystem", 
  repos = "http://cran.us.r-project.org",
  dependencies = TRUE)

# Load libraries
library(tidyverse)
library(caret)
library(data.table)
library(ggplot2)
library(ggthemes)
library(lubridate)
library(corrplot)
library(recosystem)
library(knitr)
library(kableExtra)
library(tinytex)
library(scales)
library(tidyr)
library(lubridate)
library(stringr)
library(corrplot)
library(recosystem)
```

```{r functions, configurations and datasets, include=FALSE}
# Knit options
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align="center", 
                      out.width="80%")

# RMSE function
RMSE <- function(true_rating, predicted_rating){
  sqrt(mean((true_rating - predicted_rating)^2))
}  

# Multiplot function
# Code copied from 
# https://stackoverflow.com/questions/24387376/r-error-could-not-find-function-multiplot-using-cookbook-example
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
#movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
#                                           title = as.character(title),
#                                           genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

`\newpage{}`{=latex}'

## Data

The initial **R file** provided by the **edx team** contains the code required to download, clean and prepare **2 datasets** for the project.

The first dataset was named as **edx**, that will be used to verify the different algorithms. This dataset has **`r format(nrow(edx),big.mark=",")`** observations and **`r ncol(edx)`** columns. The predictor mean **rating** has a value of **`r round(mean(edx$rating),2)`** and a standard deviation of **`r round(sd(edx$rating),2)`**.

While the second dataset was named as **validation**, that will be used only with the algorithm that has the lowest **RMSE**. This dataset has **`r format(nrow(validation),big.mark=",")`** observations and **`r ncol(validation)`** columns.

Both datasets have in total **`r format(nrow(edx) + nrow(validation),big.mark=",")`** observations.

The edx´s dataset characteristics are:

```{r table-edx-characteristics, warning = FALSE, message = TRUE}
tribble(
  ~"Column name", ~"Type", ~"Characteristic", ~"Description",
  "userId", 
  class(edx$userId),"Discrete quantitative predictor", "User unique identifier",
  "movieId", 
  class(edx$movieId),"Discrete quantitative predictor", "Movie unique identifier",
  "timestamp", 
  class(edx$timestamp),"Discrete quantitative predictor", "Date and time on epoch format",
  "title", 
  class(edx$title),"Nominal qualitative predictor", "Movie title that is not unique",
  "genres", 
  class(edx$genres),"Nominal qualitative predictor", "Movie genre classification that is not unique",
  "rating", 
  class(edx$rating), "Outcome and that is continuous", "Movie rating from 0 to 5") %>% 
  kbl(., booktabs = T, caption = "MovieLens dataset characteristics") %>% kable_styling(latex_options = "HOLD_position") %>% row_spec(0, bold = T)

```

The first edx´s records are:

```{r table-edx-first-records, warning = FALSE, message = TRUE}
head(edx) %>% kbl(., booktabs = T, caption = "edx dataset first records") %>% 
  kable_styling(latex_options = "HOLD_position") %>% row_spec(0, bold = T)

```

### About users

```{r users, warning = FALSE, message = TRUE}
users <-edx %>% group_by(userId) %>% summarize(reviews = n(),avg_rating=mean(rating))
users_mean <- mean(users$reviews)
users_below_mean <- users %>% 
  filter(reviews < round(mean(users$reviews))) %>% nrow()
users_above_mean <- users %>% 
  filter(reviews > round(mean(users$reviews))) %>% nrow()
user_top <- users %>% 
  filter(reviews >= max(reviews)) %>% 
  pull(userId)
```

On edx dataset there are **`r format(n_distinct(edx$userId), big.mark=",")`** unique users and on average every user rates approximately **`r round(users_mean)`** movies. There are **`r format(users_below_mean,big.mark=",")`** users _(`r round((users_below_mean/nrow(users))*100)`%)_ that rated less than **`r round(users_mean)`** movies and **`r format(users_above_mean,big.mark=",")`** _(`r round((users_above_mean/nrow(users))*100)`%)_ users that rated more than **`r format(round(users_mean),big.mark=",")`** movies. 

About the amount of movies reviewed per user, only **`r users %>% filter(reviews > 5000) %>% nrow()`** have evaluated more than **5,000 movies** each one, being user **`r user_top`** the top who has evaluated **`r users %>% filter(reviews >= max(reviews)) %>% pull(reviews) %>% format(.,big.mark=",")`** movies.

```{r table-users-rating, warning = FALSE, message = TRUE}
tribble(
  ~"Movies reviewed per user", ~"# users",  ~"%", ~"avg_rating",
  "Below 129", users %>% filter(reviews < users_mean) %>% nrow(),100*(users %>% filter(reviews < users_mean) %>% nrow())/(nrow(users)),users %>% filter(reviews < users_mean) %>% summarize(mean(avg_rating)),
  "Between 130 and 500", users %>% filter(reviews > users_mean & reviews < 500) %>% nrow(),100*(users %>% filter(reviews > users_mean & reviews < 500) %>% nrow())/(nrow(users)),users %>% filter(reviews > users_mean & reviews < 500) %>% summarize(mean(avg_rating)),
  "Between 501 and 1,000", users %>% filter(reviews > 500 & reviews < 1000) %>% nrow(),100*(users %>% filter(reviews > 500 & reviews < 1000) %>% nrow())/(nrow(users)),users %>% filter(reviews > 500 & reviews < 1000) %>% summarize(mean(avg_rating)),
  "Between 1,001 and 2,000", users %>% filter(reviews > 1000 & reviews < 2000) %>% nrow(),100*(users %>% filter(reviews > 1000 & reviews < 2000) %>% nrow())/(nrow(users)),users %>% filter(reviews > 1000 & reviews < 2000) %>% summarize(mean(avg_rating)),
  "Between 2,001 and 3,000", users %>% filter(reviews > 2000 & reviews < 3000) %>% nrow(),100*(users %>% filter(reviews > 2000 & reviews < 3000) %>% nrow())/(nrow(users)),users %>% filter(reviews > 2000 & reviews < 3000) %>% summarize(mean(avg_rating)),
  "Between 3,001 and 4,000", users %>% filter(reviews > 3000 & reviews < 4000) %>% nrow(),100*(users %>% filter(reviews > 3000 & reviews < 4000) %>% nrow())/(nrow(users)),users %>% filter(reviews > 3000 & reviews < 4000) %>% summarize(mean(avg_rating)),
  "Between 4,001 and 5,000", users %>% filter(reviews > 4000 & reviews < 5000) %>% nrow(),100*(users %>% filter(reviews > 4000 & reviews < 5000) %>% nrow())/(nrow(users)),users %>% filter(reviews > 4000 & reviews < 5000) %>% summarize(mean(avg_rating)),
  "More than 5,001", users %>% filter(reviews > 5000) %>% nrow(),100*(users %>% filter(reviews > 5000) %>% nrow())/(nrow(users)),users %>% filter(reviews > 5000) %>% summarize(mean(avg_rating))
  ) %>%
  kbl(
    ., 
    booktabs = T, 
    caption = "Movies reviewed per user",
    format.args = list(big.mark = ","),
    digits = c(3, 4)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)

```

An histogram that displays the amount of movies reviewed by users.

```{r histogram-userid, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="UserId histogram"}

edx %>% count(userId) %>% 
  ggplot(aes(n)) +
  geom_histogram(bins=100, fill = "blue", color = "green") +
  scale_x_continuous(labels=comma) +
  scale_y_continuous(labels=comma) +
  geom_vline(
    xintercept = mean(users$reviews), 
    col = "red", 
    linetype = "dashed") +
  annotate(
    "text",
    x = 1500,
    y = 22000,
    label = "mean: 129 movies reviewed per user", 
    color = "red", size = 3) +
  labs(
    x="# movies reviewed by user", 
    y="# users", caption = "source data: edx dataset") +
  theme_hc() + ggtitle("Users") 
    
```

### About movies

```{r movies, warning = FALSE, message = TRUE}
movies <-edx %>% group_by(movieId) %>% summarize(reviews = n(), avg_rating=mean(rating))
movies_mean <- mean(movies$reviews)
movies_below_mean <- movies %>% 
  filter(reviews < round(mean(movies$reviews))) %>% nrow()
movies_above_mean <- movies %>% 
  filter(reviews > round(mean(movies$reviews))) %>% nrow()
movie_top <- movies %>% 
  filter(reviews >= max(reviews)) %>% 
  pull(movieId)

```

There are **`r format(n_distinct(edx$movieId), big.mark=",")`** unique movies. **`r edx %>% group_by(movieId) %>% summarize(count = n()) %>% filter(count == 1) %>% nrow()`** movies were evaluated only once by **`r edx %>% group_by(movieId) %>% summarize(count = n(),avg=mean(rating)) %>% filter(count == 1)  %>% left_join(edx, by = "movieId") %>% group_by(userId) %>% summarize(count=n()) %>% nrow() `** users. **`r format(movies_below_mean,big.mark=",")`** movies _(`r round((movies_below_mean/nrow(movies))*100)`%)_ were rated less than **`r round(movies_mean)`** times by users and **`r format(movies_above_mean,big.mark=",")`** _(`r round((movies_above_mean/nrow(movies))*100)`%)_ movies were rated more than **`r round(movies_mean)`** times by users, being movie **`r movie_top`** the top which has been evaluated by **`r movies %>% filter(reviews >= max(reviews)) %>% pull(reviews) %>% format(.,big.mark=",")`** users. The **title** of this movie is **"`r edx %>% filter(movieId==movie_top)%>% select(title) %>% head(1)`"** and the **genres** are **"`r edx %>% filter(movieId==movie_top)%>% select(genres) %>% head(1)`"**.

```{r table-movie-rating, warning = FALSE, message = TRUE}
tribble(
  ~"Movies reviewed", ~"# movies",  ~"%", ~"avg_rating",
  "Below 843", movies %>% filter(reviews < 843) %>% nrow(),100*(movies %>% filter(reviews < 843) %>% nrow())/(nrow(movies)),movies %>% filter(reviews < 843) %>% summarize(mean(avg_rating)),
  "Between 843 and 5,000", movies %>% filter(reviews > 843 & reviews < 5000) %>% nrow(),100*(movies %>% filter(reviews > 843 & reviews < 5000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 843 & reviews < 5000) %>% summarize(mean(avg_rating)), 
  "Between 5,001 and 10,000", movies %>% filter(reviews > 5000 & reviews < 10000) %>% nrow(),100*(movies %>% filter(reviews > 5000 & reviews < 10000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 5000 & reviews < 10000) %>% summarize(mean(avg_rating)),
  "Between 10,001 and 15,000", movies %>% filter(reviews > 10000 & reviews < 15000) %>% nrow(),100*(movies %>% filter(reviews > 10000 & reviews < 15000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 10000 & reviews < 15000) %>% summarize(mean(avg_rating)),
  "Between 15,001 and 20,000", movies %>% filter(reviews > 15000 & reviews < 20000) %>% nrow(),100*(movies %>% filter(reviews > 15000 & reviews < 20000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 15000 & reviews < 20000) %>% summarize(mean(avg_rating)),
  "Between 20,001 and 25,000", movies %>% filter(reviews > 20000 & reviews < 25000) %>% nrow(),100*(movies %>% filter(reviews > 20000 & reviews < 25000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 20000 & reviews < 25000) %>% summarize(mean(avg_rating)),
  "Between 25,001 and 30,000", movies %>% filter(reviews > 25000 & reviews < 30000) %>% nrow(),100*(movies %>% filter(reviews > 25000 & reviews < 30000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 25000 & reviews < 30000) %>% summarize(mean(avg_rating)),
  "More than 30,000", movies %>% filter(reviews > 30000) %>% nrow(),100*(movies %>% filter(reviews > 30000) %>% nrow())/(nrow(movies)),movies %>% filter(reviews > 30000) %>% summarize(mean(avg_rating)),
  ) %>%
  kbl(
    ., 
    booktabs = T, 
    caption = "Movies reviewed",
    format.args = list(big.mark = ","),
    digits = c(3, 4)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)

```

An histogram that displays the number of movies reviewed by users (some of them are more rated than others) is:

```{r histogram-movieid, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="MovieId histogram"}
edx %>% count(movieId) %>% 
  ggplot(aes(n)) +
  geom_histogram(bins=100, fill = "blue", color = "green") +
  scale_x_continuous(labels=comma) +
  scale_y_continuous(labels = comma) +
  geom_vline(
    xintercept = mean(movies$reviews), 
    col = "red", 
    linetype = "dashed") +
  annotate(
    "text",
    x = 6500,
    y = 5000,
    label = "mean: 843 reviews per movie", 
    color = "red", size = 3) +
  labs(
    x="# of reviews per movie", 
    y="# movies", caption = "source data: edx dataset") +
  theme_hc() + ggtitle("Movies") 
    
```

In order to _verify_ how **sparse** is the relationship between users and movies, this graph take a sample of **500** users.

```{r sparse-matrix-users-movies, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Sparse matrix - Movies vs Users"}
samples <- 500
users_sample <- sample(unique(edx$userId), samples)
edx %>% filter(userId %in% users_sample) %>%
  select(userId, movieId, rating) %>%
  mutate(rating = 1) %>%
  spread(movieId, rating) %>%
  select(sample(ncol(.), samples)) %>%
  as.matrix() %>% t(.) %>%
  image(1:samples, 1:samples, . , xlab="Movies", ylab="Users")
```

### About timestamp

**Timestamp** is on [epoch format][epoch_format], so it will be transformed to verify the behavior using a _scatterplot_ with different time scales. The first date in which a movie was rated was **`r as.Date(as.POSIXct(min(edx$timestamp), origin="1970-01-01"))`** and the last one is **`r as.Date(as.POSIXct(max(edx$timestamp), origin="1970-01-01"))`**.

```{r scatterplot-timestamp-rating, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Timestamp versus rating"}
timestamp_day <- edx %>% 
  mutate(date = round_date(as_datetime(timestamp), unit = "day")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth() +
  labs(caption = "source data: edx set") +
  theme_hc() + ggtitle("Date using day versus rating")

timestamp_week <- edx %>% 
  mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth() +
  labs(caption = "source data: edx set") +
  theme_hc() + ggtitle("Date using week versus rating")

timestamp_month <- edx %>% 
  mutate(date = round_date(as_datetime(timestamp), unit = "month")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth() +
  labs(caption = "source data: edx set") +
  theme_hc() + ggtitle("Date using month versus rating")

timestamp_year <- edx %>% 
  mutate(date = round_date(as_datetime(timestamp), unit = "year")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth() +
  labs(caption = "source data: edx set") +
  theme_hc() + ggtitle("Date using year versus rating")

multiplot(timestamp_day,
          timestamp_month,
          timestamp_week,
          timestamp_year,
          cols = 2)

```
### About title

The **top 5** and **worst 5** title´s movies based on reviews and average rating are:

```{r table-best-titles-rating, warning = FALSE, message = TRUE}
edx %>%
  group_by(title) %>%
  summarize(reviews=n(), avg_rating=mean(rating)) %>%
  arrange(desc(reviews)) %>%
  head(5) %>%
  kbl(
    ., 
    booktabs = T, 
    caption = "Best titles movies",
    format.args = list(big.mark = ","),
    digits = c(3, 4)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)
```

```{r table-worst-titles-rating, warning = FALSE, message = TRUE}
edx %>%
  group_by(title) %>%
  summarize(reviews=n(), avg_rating=mean(rating)) %>%
  arrange(reviews) %>%
  head(5) %>%
  kbl(
    ., 
    booktabs = T, 
    caption = "Worst titles movies",
    format.args = list(big.mark = ","),
    digits = c(3, 4)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)
```


```{r top-5-movies-title, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Movies titles most reviewed"}

edx %>%
  group_by(title) %>%
  summarize(reviews=n()) %>%
  arrange(desc(reviews)) %>%
  head(5) %>%
  ggplot(aes(x=reorder(title, reviews), y=reviews)) +
  geom_bar(stat='identity', fill="blue", line="green") +
  coord_flip(y=c(0, 32000)) +
  labs(x= "", y="# reviews") +
  geom_text(aes(label= reviews), 
            position = position_stack(vjust= 0.5), 
            colour = "white", size = 4) +
  theme_hc() + 
  labs(title="Top 5 movies title \n based on reviews" , 
       caption = "source data: edx set")
```

```{r worst-5-movies-title, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Movies titles less reviewed"}

edx %>%
  group_by(title) %>%
  summarize(reviews=n()) %>%
  arrange(reviews) %>%
  head(5) %>%
  ggplot(aes(x=reorder(title, reviews), y=reviews)) +
  geom_bar(stat='identity', fill="blue", line="green") +
  coord_flip(y=c(0, 3)) +
  labs(x= "", y="# reviews") +
  geom_text(aes(label= reviews), 
            position = position_stack(vjust= 0.5), 
            colour = "white", size = 4) +
  theme_hc() + 
  labs(
    title="Worst 5 movies title \n based on reviews",
    caption = "source data: edx set")
```

Additionally, **title** column contains inside a _parenthesis_ the year in which the movie was released, so **year_released** is a new column that contains parsed value. It´s interesting that movies around _1940_ have a higher rating and for movies after _1970_ the average rating has been decreasing maybe for the variety or generational change.

```{r year-released-rating, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Year released rating"}

edx <- edx %>% mutate(year_released = as.numeric(str_sub(title,-5,-2)))

edx %>% 
     group_by(year_released) %>%
     summarize(rating = mean(rating)) %>%
     ggplot(aes(year_released, rating)) +
     geom_point() +
     geom_smooth() +
     labs(
       x= "year released", 
       caption = "source data: edx set") +
     theme_hc() + ggtitle("Movie year released rating")

```

### About genres

```{r genres-parsed, warning = FALSE, message = FALSE}

genres_parsed <- str_replace(edx$genres,"\\|.*","")
genres_parsed <- data.table(genres_parsed)

top_genres<- edx %>% 
  group_by(genres) %>% 
  summarize(reviews = n(), avg_rating=mean(rating)) %>%
  arrange(desc(reviews)) %>% top_n(10) %>% pull(genres)

```

Several **genres** are indicated per movie. There are **`r n_distinct(edx$genres)`** genres being the **10** most reviewed:

```{r table-genres, warning = FALSE, message = FALSE}

edx %>% group_by(genres) %>% 
  summarize(reviews = n(), avg_rating=mean(rating)) %>%
  arrange(desc(reviews)) %>% top_n(10) %>% 
  kbl(., 
      booktabs = T, 
      caption = "Genres reviews and rating", 
      format.args = list(big.mark = ","),
      digits = c(3,3)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)
```

In addition the **|** _(pipe)_ is used as delimiter and once parsed there are **`r genres_parsed %>% group_by(genres_parsed) %>% summarize(reviews = n()) %>% nrow()`** unique genres with the following reviews:

```{r table-genres-reviews, warning = FALSE, message = TRUE}

genres_list <-genres_parsed %>% 
     group_by(genres_parsed) %>% 
     summarize(reviews = n()) %>% 
     arrange(desc(reviews)) %>% select(genres_parsed)

genres_rating <- sapply(genres_list, function(genre){
  index <- str_which(edx$genres, genre) 
  mean(edx$rating[index], na.rm = T)
})

genres_parsed %>% 
  group_by(genres_parsed) %>% 
  summarize(reviews = n()) %>% 
  arrange(desc(reviews)) %>%
  kbl(., 
      booktabs = T, 
      caption = "Genres reviews", 
      format.args = list(big.mark = ",")) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)
```

### About rating

An histogram that displays the rating distribution is:

```{r histogram-rating, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Rating histogram"}
ggplot(edx, aes(x= rating)) +
  geom_histogram(binwidth = 0.25, fill = "blue") +
  geom_vline(xintercept = mean(edx$rating), col = "red", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 5, by = 0.5)) +
  scale_y_continuous(labels = comma, breaks = c(seq(0, 3000000, 500000))) +
  labs(x = "rating", y = "# reviews", caption = "source data: edx dataset") + 
  annotate(
    "text",
    x = 3.3, 
    y = 2700000, 
    label = "mean", 
    color = "red", 
    size = 3) +
  theme_hc() + ggtitle("Rating")
```

An histogram about the ratings from the user **(`r user_top`)** with the maximum amount of reviews is:

```{r histogram-rating-top-user, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Rating histogram for most rated user"}
edx %>% filter(userId==user_top) %>%
ggplot(., aes(x= rating)) +
  geom_histogram(binwidth = 0.25, fill = "blue") +
  geom_vline(xintercept = edx %>% filter(userId==user_top) %>% summarize(mean(rating)) %>% pull(), col = "red", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 5, by = 0.5)) +
  scale_y_continuous(labels = comma, breaks = c(seq(0, 3000, 500))) +
  labs(x = "rating", y = "# reviews", caption = "source data: edx dataset") +
  annotate(
    "text",
    x = 3.5, 
    y = 2300, 
    label = "mean", 
    color = "red", 
    size = 3) +
  theme_hc() + ggtitle("Rating for user 59269")
```

An histogram about the movie most rated **"`r edx %>% filter(movieId==movie_top)%>% select(title) %>% head(1)`"** is:

```{r histogram-rating-top-movie, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Rating histogram for most rated user"}
edx %>% filter(movieId==movie_top) %>%
ggplot(., aes(x= rating)) +
  geom_histogram(binwidth = 0.25, fill = "blue") +
  geom_vline(xintercept = edx %>% filter(movieId==movie_top) %>% summarize(mean(rating)) %>% pull(), col = "red", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 5, by = 0.5)) +
  scale_y_continuous(labels = comma, breaks = c(seq(0, 16000, 2000))) +
  labs(x = "rating", y = "# reviews", caption = "source data: edx dataset") +
  annotate(
    "text",
    x = 4.4, 
    y = 13000, 
    label = "mean", 
    color = "red", 
    size = 3) +
  theme_hc() + ggtitle("Rating for movie \"Pulp Fiction\"")
```

About the **genres** rating for the most reviewed that is **"`r top_genres[1]`"** the histogram shows favorable reviews.

```{r histogram-rating-genres_top, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Rating histogram for genres \"Crime|Mystery|Thriller\""}

edx %>% filter(genres==top_genres[1]) %>%
ggplot(., aes(x= rating)) +
  geom_histogram(binwidth = 0.25, fill = "blue") +
  geom_vline(xintercept = edx %>% filter(genres==top_genres[1]) %>% summarize(mean(rating)) %>% pull(), 
    col = "red", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 5, by = 0.5)) +
  scale_y_continuous(labels = comma) +
  labs(x = "rating", y = "# reviews", caption = "source data: edx dataset") +
  annotate(
    "text",
    x = 4.4, 
    y = 9000, 
    label = "mean", 
    color = "red", 
    size = 3) +
  theme_hc() + ggtitle("Rating for genres \"Crime|Mystery|Thriller\"")

```

`\newpage{}`{=latex}'

# Results

## About RMSE

The formula used to obtain the loss function is:

$$RMSE = \sqrt{\frac{1}{N}\sum_{u,i}{(\hat{y}_{u,i}-y_{u,i})^2}}$$

$y_{u,i}$ is the rating for movie by user

$\hat{y}_{u,i}$ is the prediction 

**N** is the user/movie combinations

## About train and test datasets

```{r train-test-set, warning = FALSE, message = FALSE}
set.seed(1, sample.kind = "Rounding")

# Split edx dataset into test and train set
testing_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
train_set <- edx[-testing_index,]
test_set <- edx[testing_index,]

# To make sure test set contains all movieId, userId from train set
test_set <- test_set %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")
```

**edx** dataset is splitted on another 2 datasets:

* **train_set** contains **`r format(nrow(train_set), big.mark=",")`** observations that will be used with every algorithm.
* **test_set** contains **`r format(nrow(test_set), big.mark=",")`** observations that will be used at the moment to obtain the respective **RMSE**.

## Models

The model to be developed is **lineal** considering the mean **$\mu$** that is the **true** value and the error **$\epsilon_{u,i}$** (independent errors sampled from the same distribution centered at 0) the following initial formula:

$$Y_{u,i}=\mu + \epsilon_{u,i}$$

## Algorithms

### First model - Average rating of all movies across all users

```{r first-model, warning = FALSE, message = FALSE}
options(digits = 6) 

# Calculate average rating
mu <- mean(train_set$rating)

# Obtain the RMSE of this model
first_model_mu <- RMSE(test_set$rating,mu)

# Store the results on a dataframe
# Append the RMSE target to the dataframe
RMSE.results <- data_frame(
    Algorithm = "Model #1 - Average rating movie",
    RMSE = first_model_mu)

```

The formula used on this model is:

$$Y_{u,i}=\mu + \epsilon_{u,i}$$

This algorithm generates the following RMSE value: **`r first_model_mu`**.

### Second model - Movie effect

```{r second-model, warning = FALSE, message = FALSE}

# Calculate the bias on rating for movie
movie_avg <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_movie = mean(rating - mu)) 

# Calculate predicted values using test_set
predictions_b_movie <- mu + test_set %>%
  left_join(movie_avg, by = "movieId") %>% pull(b_movie)

# If there is a NA when using this effect, replace it with mu
predictions_b_movie <- replace_na(predictions_b_movie, mu)

# Obtain the RMSE of this model
second_model_movie_effect <- RMSE(test_set$rating,predictions_b_movie)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(Algorithm = "Model #2 - Movie effect",
             RMSE = second_model_movie_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{i} + \epsilon_{u,i}$$

This algorithm generates the following RMSE value: **`r second_model_movie_effect`**.

The following histogram shows the impact of this bias that is skewed to the left.

```{r bias-movie, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Bias movie"}

ggplot(movie_avg, aes(x= b_movie)) +
  geom_histogram(
    binwidth = 0.05, 
    fill = "blue", 
    color="green") +
  scale_x_continuous(
    breaks = seq(round(min(movie_avg$b_movie)),
                 round(max(movie_avg$b_movie)), 
                 by = 0.5)) + 
  scale_y_continuous(labels = comma) +
  labs(
    x = "bias movie", 
    y = "# reviews", 
    caption = "source data: edx dataset") +
  theme_hc() +
  ggtitle("Bias movie effect on rating")
```

The **15 best movies** with this bias are:

```{r second-model-best-movies, warning = FALSE, message = FALSE}
train_set %>% 
  select(-timestamp) %>%
  left_join(movie_avg,by="movieId") %>%
  group_by(movieId,title) %>%
  summarize(
    users = n(), 
    rat_avg = mean(rating),
    bi_avg = mean(b_movie)) %>%
  arrange(desc(bi_avg)) %>%
  head(15)%>%
  kbl(
    ., 
    booktabs = T, 
    caption = "15 best movies related to bias movie",
    digits = c(3, 3)) %>%
  kable_styling(
    latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)
```

The **15 worst movies** with this bias are:

```{r second-model-worst-movies, warning = FALSE, message = FALSE}
train_set %>% 
  select(-timestamp) %>%
  left_join(movie_avg,by="movieId") %>%
  group_by(movieId,title) %>%
  summarize(
    users = n(), 
    rat_avg = mean(rating),
    bi_avg = mean(b_movie)) %>%
  arrange(bi_avg) %>%
  head(15)%>%
  kbl(
    ., 
    booktabs = T, 
    caption = "15 worst movies related to bias movie",
    digits = c(3, 3)) %>%
  kable_styling(
    latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)
```

### Third model - User effect

```{r third-model, warning = FALSE, message = FALSE}

# Calculate the bias on rating for user
user_avg <- train_set %>% 
  group_by(userId) %>%
  summarize(b_user = mean(rating - mu))

# Calculate predicted values using test_set
predictions_b_user <- mu + test_set %>%
  left_join(user_avg, by = "userId") %>% pull(b_user)

# If there is a NA when using this effect, replace it with mu
predictions_b_user <- replace_na(predictions_b_user, mu)

# Obtain the RMSE of this model
third_model_user_effect <- RMSE(test_set$rating,predictions_b_user)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(Algorithm = "Model #3 - User effect",
             RMSE = third_model_user_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{u} + \epsilon_{u,i}$$

This algorithm generates the following RMSE value: **`r third_model_user_effect`**.

The following histogram shows the impact of this bias that is skewed to the left.

```{r bias-user, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Bias user"}

ggplot(user_avg, aes(x= b_user)) +
  geom_histogram(
    binwidth = 0.05, 
    fill = "blue", 
    color="green") +
  scale_x_continuous(
    breaks = seq(round(min(user_avg$b_user)),
                 round(max(user_avg$b_user)), 
                 by = 0.5)) +
  scale_y_continuous(labels = comma) +
  labs(
    x = "bias user", 
    y = "# reviews", 
    caption = "source data: edx dataset") +
  theme_hc() +
  ggtitle("Bias user effect on rating")
```

The **15 best users** with this bias are:

```{r third-model-best-users, warning = FALSE, message = FALSE}
train_set %>% 
  select(-timestamp) %>%
  left_join(user_avg,by="userId") %>% 
  group_by(userId) %>%
  summarize(
    movies_rated=n(),
    rating_avg=mean(rating),
    b_user_avg=mean(b_user)) %>%
  arrange(desc(b_user_avg)) %>%
  head(15) %>% kbl(
        ., 
        booktabs = T, 
        caption = "15 best users related to bias user",
        digits = c(3, 3)) %>%
    kable_styling(
        latex_options = "HOLD_position") %>%
    row_spec(0, bold = T)  
```

The **15 worst users** with this bias are:

```{r third-model-worst-users, warning = FALSE, message = FALSE}
train_set %>% 
  select(-timestamp) %>%
  left_join(user_avg,by="userId") %>% 
  group_by(userId) %>%
  summarize(
    movies_rated=n(),
    rating_avg=mean(rating),
    b_user_avg=mean(b_user)) %>%
  arrange(b_user_avg) %>%
  head(15) %>% kbl(
        ., 
        booktabs = T, 
        caption = "15 worst users related to bias user",
        digits = c(3, 3)) %>%
    kable_styling(
        latex_options = "HOLD_position") %>%
    row_spec(0, bold = T)  
```

### Fourth model - Movie plus User effect

```{r fourth-model, warning = FALSE, message = FALSE}

# Calculate predicted values using test_set using movie and user effect
predictions_b_movie_b_user <- test_set %>%
  left_join(movie_avg, by='movieId') %>%
  left_join(user_avg, by='userId') %>%
  mutate(predicted = mu + b_movie + b_user) %>% pull(predicted)
  
# If there is a NA when using this effect, replace it with mu
predictions_b_movie_b_user <- replace_na(predictions_b_movie_b_user, mu)

# Obtain the RMSE of this model
fourth_model_movie_user_effect <- RMSE(test_set$rating,predictions_b_movie_b_user)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(Algorithm = "Model #4 - Movie plus User effect",
             RMSE = fourth_model_movie_user_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{i} + b_{u} + \epsilon_{u,i}$$

This algorithm generates the following RMSE value: **`r fourth_model_movie_user_effect`**.

### Fifth model - Date effect

```{r fifth-model, warning = FALSE, message = FALSE}

# Calculate the bias on rating for date
date_avg <- train_set %>%
  mutate(date = round_date(as_datetime(timestamp), unit = "day")) %>%
  group_by(date) %>%
  summarize(b_date = mean(rating - mu))

# Change format to "yyyy-mm-dd" on "date" variable
date_avg$date <- format(date_avg$date, "%F")

# Add to test_set a new variable "date" converting from epoc
test_set <- test_set %>%
  mutate(date = as.POSIXct(timestamp, origin = "1970-01-01", tz = "GMT"))

# Change format to "yyyy-mm-dd" on "date" variable
test_set$date <- format(test_set$date,"%F")

# Calculate predicted values using test_set
predictions_b_date <- mu + test_set %>%
  left_join(date_avg, by = "date") %>% pull(b_date)

# If there is a NA when using this effect, replace it with mu
predictions_b_date <- replace_na(predictions_b_date, mu)

# Obtain the RMSE of this model
fifth_model_date_effect <- RMSE(test_set$rating,predictions_b_date)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(Algorithm = "Model #5 - Date effect",
             RMSE = fifth_model_date_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{date} + \epsilon_{u,i}$$

This algorithm generates the following RMSE value: **`r fifth_model_date_effect`**.

The following histogram shows the impact of this bias that is not skewed.

```{r bias-date, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Bias date"}
ggplot(date_avg, aes(x= b_date)) +
  geom_histogram(
    binwidth = 0.05, 
    fill = "blue", 
    color="green") +
  scale_x_continuous(
    breaks =seq(round(min(date_avg$b_date)),
                round(max(date_avg$b_date)), 
                by = 0.5)) +
  scale_y_continuous(labels = comma) +
  labs(
    x = "bias date", 
    y = "# reviews", 
    caption = "source data: edx dataset") +
  theme_hc() +
  ggtitle("Bias date effect on rating")

```

### Sixth model - Movie plus User plus Date effect

```{r sixth-model, warning = FALSE, message = FALSE}

# Calculate predicted values using test_set using movie, user and date effect
predictions_b_movie_b_user_b_date <- test_set %>%
  left_join(movie_avg, by='movieId') %>%
  left_join(user_avg, by='userId') %>%
  left_join(date_avg, by="date") %>%
  mutate(predicted = mu + b_movie + b_user + b_date) %>% pull(predicted)

# If there is a NA when using this effect, replace it with mu
predictions_b_movie_b_user_b_date <- replace_na(predictions_b_movie_b_user_b_date, mu)

# Obtain the RMSE of this model
sixth_model_movie_user_date_effect <- RMSE(test_set$rating,predictions_b_movie_b_user_b_date)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(
    Algorithm = "Model #6 - Movie plus User plus Date effect",
    RMSE = sixth_model_movie_user_date_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{i} + b_{u} + b_{date} + \epsilon_{u,i,date}$$

This algorithm generates the following RMSE value: **`r sixth_model_movie_user_date_effect`**.

### Septh model - Genres effect

```{r septh-model, warning = FALSE, message = FALSE}

# Calculate the bias on rating for genre
genres_avg <- train_set %>%
  group_by(genres) %>%
  summarize(b_genres = mean(rating - mu))

# Calculate predicted values using test_set
predictions_b_genres <- mu + test_set %>%
  left_join(genres_avg, by = "genres") %>% pull(b_genres)

# If there is a NA when using this effect, replace it with mu
predictions_b_genres <- replace_na(predictions_b_genres, mu)

# Obtain the RMSE of this model
septh_model_genres_effect <- RMSE(test_set$rating,predictions_b_genres)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(
    Algorithm = "Model #7 - Genres effect",
    RMSE = septh_model_genres_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{genres} + \epsilon_{u,i}$$

This algorithm generates the following RMSE value: **`r septh_model_genres_effect`**.

The following histogram shows the impact of this bias that is skewed to the left.

```{r bias-genres, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Bias date"}
ggplot(genres_avg, aes(x= b_genres)) +
  geom_histogram(
    binwidth = 0.05, 
    fill = "blue", color="green") +
  scale_x_continuous(
    breaks =  seq(round(min(genres_avg$b_genres)),
                  round(max(genres_avg$b_genres)), 
                  by = 0.5)) +
  labs(
    x = "bias genres", 
    y = "# reviews", 
    caption = "source data: edx dataset") +
  theme_hc() +
  ggtitle("Bias genres effect on rating")

```

### Eighth model - Movie plus User plus Date plus Genres effect

```{r eigth-model, warning = FALSE, message = FALSE}

# Calculate predicted values using test_set using movie, user,
# date and genres effect
predictions_b_movie_b_user_b_date_b_genres <- test_set %>%
  left_join(movie_avg, by='movieId') %>%
  left_join(user_avg, by='userId') %>%
  left_join(date_avg, by="date") %>%
  left_join(genres_avg, by="genres") %>%
  mutate(predicted = mu + b_movie + b_user + b_date + b_genres) %>% pull(predicted)

# If there is a NA when using this effect, replace it with mu
predictions_b_movie_b_user_b_date_b_genres <- replace_na(predictions_b_movie_b_user_b_date_b_genres, mu)

# Obtain the RMSE of this model
eighth_model_movie_user_date_genres_effect <- RMSE(test_set$rating,predictions_b_movie_b_user_b_date_b_genres)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(
    Algorithm = "Model #8 - Movie plus User plus Date plus Genres effect",
    RMSE = eighth_model_movie_user_date_genres_effect ))

```

The formula used on this model is:

$$Y_{u,i}=\mu + b_{i} + b_{u} + b_{date} + b_{genres} + \epsilon_{u,i,date,genres}$$

This algorithm generates the following RMSE value: **`r eighth_model_movie_user_date_genres_effect`**.

### Correlation between predictors

```{r correlation-variables, warning = FALSE, message = FALSE}
# Create a dataframe using the "ratings" and "user´s bias prediction"
ratings_results <- cbind(
  test_set$rating,
  predictions_b_user)

# Append the dataframe created with "movie´s bias prediction"
ratings_results <- cbind(
  ratings_results,
  predictions_b_movie)

# Append the dataframe created with "date´s bias prediction"
ratings_results <- cbind(
  ratings_results,
  predictions_b_date)

# Append the dataframe created with "genres´ bias prediction"
ratings_results <- cbind(
  ratings_results,
  predictions_b_genres)

# Append the dataframe created with "movie´s and user´s bias prediction"
ratings_results <- cbind(
  ratings_results,
  predictions_b_movie_b_user)

# Append the dataframe created with "movie´s, user´s and date´s bias prediction"
ratings_results <- cbind(
  ratings_results,
  predictions_b_movie_b_user_b_date)

# Append the dataframe created with "movie´s, user´s, date´s and genres´ bias prediction"
ratings_results <- cbind(
  ratings_results,
  predictions_b_movie_b_user_b_date_b_genres)

# Change the columns name
colnames(ratings_results) <- c("rating", "user","movie","date","genres","mov_usr","m_u_d","m_u_d_g")

# Calculate and store the correlations
ratings_correlations <- cor(ratings_results)

```

The following correlogram shows the rating´s relationship between the different predictors which is higher with the combination of the **movie** and **user** effect. This can be validated with the RMSE obtained (model 4) but as it was indicated in the previous sections, there are users that rate few time the movies and also movies that are rated only once and this has an effect on the RMSE.

```{r correlogram-variables, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Correlogram"}

corrplot(ratings_correlations, 
         type = "lower",
         insig = "blank",
         method = "number",
         tl.cex = 0.8, 
         cl.cex = 0.65)
```

### Regularization

By now the results obtained are far from the target, so another techniques need to be applied and one is the regularization which constrains the total variability of the effect sizes by penalizing large estimates that come from small sample sizes.

So **lambda** calculation will be done to obtain the minimal value that generates a lower RMSE.

#### Nineth model - Regularized Movie effect

```{r nineth-model, warning = FALSE, message = FALSE}

# Define incremental lambdas values
lambdas <- seq(0, 10, 0.25)

# Function to calculate RMSEs using different lambdas
rmses_reg_movie_effect <- sapply(lambdas, function(lambda){
  
  # Mean
  mu <- mean(train_set$rating)
  
  # Movie effect
  movie_avg <- train_set %>%
    group_by(movieId) %>%
    summarize(reg_movie = sum(rating - mu)/(n()+lambda))
  
  # Predictions: mu + reg_movie
  predictions_reg_movie_effect <- test_set %>% 
    left_join(movie_avg, by = "movieId") %>%
    mutate(predicted = mu + reg_movie) %>% 
    pull(predicted)
    
  return(RMSE(test_set$rating,predictions_reg_movie_effect))
  
})

```

For this model is required to obtain a **penalty** term $\lambda$ as indicated in the following graph, being **`r lambdas[which.min(rmses_reg_movie_effect)]`** the value obtained.

```{r lambda-movie, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Lambda versus RMSE for regularized movie effect"}

# Plot relationship between lambdas and RMSEs
qplot(lambdas, 
      rmses_reg_movie_effect,
      xlab = "Lambdas", 
      ylab = "RMSE", 
      colour = "lambdas",
      main = "Lambdas versus RMSE for Regularized Movie effect") +
  geom_vline(
    xintercept = lambdas[which.min(rmses_reg_movie_effect)],
    col = "blue", 
    linetype = "dashed") + 
  geom_hline(
    yintercept = rmses_reg_movie_effect[which.min(rmses_reg_movie_effect)],
    col="blue",
    linetype="dashed")

```

```{r nineth-model-rmse, echo = FALSE, warning = FALSE, message = TRUE}

# Obtain the lambda value to be used on the predictions
lambda_reg_movie_effect <- lambdas[which.min(rmses_reg_movie_effect)]

# Movie effect
reg_movie_avg <- train_set %>%
  group_by(movieId) %>%
  summarize(reg_movie = sum(rating - mu)/(n()+lambda_reg_movie_effect))

# Predictions: mu + reg_movie
predictions_reg_movie_effect <- test_set %>% 
  left_join(reg_movie_avg, by = "movieId") %>%
  mutate(predicted = mu + reg_movie) %>% 
  pull(predicted)

# Obtain the RMSE of this model
nineth_model_reg_movie_effect <- RMSE(test_set$rating,predictions_reg_movie_effect)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(
    Algorithm = "Model #9 - Regularized Movie effect",
    RMSE = nineth_model_reg_movie_effect ))

```

The formula used on this model is:

$${\frac{1}{N}\sum_{u,i}{\Big(y_{u,i}-\mu -b_{i}\Big)^2}}+\lambda\bigg(\sum_{i}{b_{i}^2}\bigg)$$

The term ${\frac{1}{N}\sum_{u,i}{\Big(y_{u,i}-\mu -b_{i}\Big)^2}}$ is used to obtain $b_{i}$ and regularized term $\lambda\bigg(\sum_{i}{b_{i}^2}\bigg)$ avoids over fitting by penalizing the magnitudes of the parameters.

By using a cross-validation the $\hat{b}_{i}$ using the adequate $\lambda$ can be found:

$${\hat{b}_{i}(\lambda)=\frac{1}{\lambda + n_{i}}\sum_{u=1}^{n_{i}}{\Big(Y_{u,i}-\hat\mu \Big)^2}}$$

This algorithm generates the following RMSE value: **`r nineth_model_reg_movie_effect`**.

#### Tenth model - Regularized User effect

```{r tenth-model, warning = FALSE, message = FALSE}

# Function to calculate RMSEs using different lambdas
rmses_reg_user_effect <- sapply(lambdas, function(lambda){
  
  # Mean
  mu <- mean(train_set$rating)
  
  # User effect
  user_avg <- train_set %>%
    group_by(userId) %>%
    summarize(reg_user = sum(rating - mu)/(n()+lambda))
  
  # Predictions: mu + reg_user
  predictions_reg_user_effect <- test_set %>% 
    left_join(user_avg, by = "userId") %>%
    mutate(predicted = mu + reg_user) %>% 
    pull(predicted)
  
  return(RMSE(test_set$rating,predictions_reg_user_effect))
  
})

```

For this model is required to obtain a **penalty** term $\lambda$ as indicated in the following graph, being **`r lambdas[which.min(rmses_reg_user_effect)]`** the value obtained.

```{r lambda-user, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Lambda versus RMSE for regularized user effect"}

# Plot relationship between lambdas and RMSEs
qplot(lambdas, 
      rmses_reg_user_effect,
      xlab = "Lambdas", 
      ylab = "RMSE", 
      colour = "lambdas",
      main = "Lambdas versus RMSE for Regularized User effect") +
  geom_vline(
    xintercept = lambdas[which.min(rmses_reg_user_effect)],
    col = "blue", 
    linetype = "dashed") + 
  geom_hline(
    yintercept = rmses_reg_user_effect[which.min(rmses_reg_user_effect)],
    col="blue",
    linetype="dashed")

```

```{r tenth-model-rmse, echo = FALSE, warning = FALSE, message = TRUE}
# Obtain the lambda value to be used on the predictions
lambda_reg_user_effect <- lambdas[which.min(rmses_reg_user_effect)]

# User effect
reg_user_avg <- train_set %>%
  group_by(userId) %>%
  summarize(reg_user = sum(rating - mu)/(n()+lambda_reg_user_effect))

# Predictions: mu + reg_user
predictions_reg_user_effect <- test_set %>% 
  left_join(reg_user_avg, by = "userId") %>%
  mutate(predicted = mu + reg_user) %>% 
  pull(predicted)

# Obtain the RMSE of this model
tenth_model_reg_user_effect <- RMSE(test_set$rating,predictions_reg_user_effect)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(Algorithm = "Model #10 - Regularized User effect",
             RMSE = tenth_model_reg_user_effect ))

```

The formula used on this model is:

$${\frac{1}{N}\sum_{u,i}{\Big(y_{u,i}-\mu -b_{u}\Big)^2}}+\lambda\bigg(\sum_{u}{b_{u}^2}\bigg)$$

The term ${\frac{1}{N}\sum_{u,i}{\Big(y_{u,i}-\mu -b_{u}\Big)^2}}$ is used to obtain $b_{u}$ and regularized term $\lambda\bigg(\sum_{u}{b_{u}^2}\bigg)$ avoids over fitting by penalizing the magnitudes of the parameters.

By using a cross-validation the $\hat{b}_{u}$ using the adequate $\lambda$ can be found:

$${\hat{b}_{u}(\lambda)=\frac{1}{\lambda + n_{i}}\sum_{u=1}^{n_{i}}{\Big(Y_{u,i}-\hat\mu\Big)^2}}$$

This algorithm generates the following RMSE value: **`r tenth_model_reg_user_effect`**.

#### Eleventh model - Regularized Movie plus Regularized User effect

```{r eleventh-model, warning = FALSE, message = FALSE}

# Function to calculate RMSEs using different lambdas
rmses_reg_movie_and_reg_user_effect <- sapply(lambdas, function(lambda){
  
  # Mean
  mu <- mean(train_set$rating)
  
  # Movie effect
  movie_avg <- train_set %>%
    group_by(movieId) %>%
    summarize(reg_movie = sum(rating - mu)/(n()+lambda))

  # User effect
  user_avg <- train_set %>%
    left_join(movie_avg, by = "movieId") %>%
    group_by(userId) %>%
    summarize(reg_user = sum(rating - mu - reg_movie)/(n()+lambda))
  
  # Predictions: mu + reg_movie + reg_user
  predictions_reg_movie_and_reg_user_effect <- test_set %>% 
    left_join(movie_avg, by = "movieId") %>%
    left_join(user_avg, by = "userId") %>%
    mutate(predicted = mu + reg_movie + reg_user) %>% 
    pull(predicted)

  return(RMSE(test_set$rating,predictions_reg_movie_and_reg_user_effect))
  
})

```

For this model is required to obtain a **penalty** term $\lambda$ as indicated in the following graph, being **`r lambdas[which.min(rmses_reg_movie_and_reg_user_effect)]`** the value obtained.

```{r lambda-movie-user, echo = FALSE, warning = FALSE, message = TRUE, fig.cap="Lambdas versus RMSE for Regularized (Movie plus User) effect"}

# Plot relationship between lambdas and RMSEs
qplot(lambdas, 
      rmses_reg_movie_and_reg_user_effect,
      xlab = "Lambdas", 
      ylab = "RMSE", 
      colour = "lambdas",
      main = "Lambdas versus RMSE for Regularized (Movie plus User) effect") +
  geom_vline(
    xintercept = lambdas[which.min(rmses_reg_movie_and_reg_user_effect)],
    col = "blue", 
    linetype = "dashed") + 
  geom_hline(
    yintercept = rmses_reg_movie_and_reg_user_effect[which.min(rmses_reg_movie_and_reg_user_effect)],
    col="blue",
    linetype="dashed")

```

```{r eleventh-model-rmse, echo = FALSE, warning = FALSE, message = TRUE}
# Obtain the lambda value to be used on the predictions
lambda_reg_user_and_reg_movie_effect <- lambdas[which.min(rmses_reg_movie_and_reg_user_effect)]

# Movie effect
reg_movie_avg <- train_set %>%
  group_by(movieId) %>%
  summarize(reg_movie = sum(rating - mu)/(n()+lambda_reg_user_and_reg_movie_effect))

# User effect
reg_user_avg <- train_set %>%
  left_join(reg_movie_avg, by = "movieId") %>%
  group_by(userId) %>%
  summarize(reg_user = sum(rating - mu - reg_movie)/(n()+lambda_reg_user_and_reg_movie_effect))

# Predictions: mu + reg_movie + reg_user
predictions_reg_movie_and_reg_user_effect <- test_set %>% 
  left_join(reg_movie_avg, by = "movieId") %>%
  left_join(reg_user_avg, by = "userId") %>%
  mutate(predicted = mu + reg_movie + reg_user) %>% 
  pull(predicted)

# Obtain the RMSE of this model
eleventh_model_reg_movie_and_reg_user_effect <- RMSE(test_set$rating,predictions_reg_movie_and_reg_user_effect)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(
    Algorithm = "Model #11 - Regularized (Movie plus User) effect",
    RMSE = eleventh_model_reg_movie_and_reg_user_effect ))

```

The formula used on this model is:

$${\frac{1}{N}\sum_{u,i}{\Big(y_{u,i}-\mu -b_{u}-b_{i}\Big)^2}}+\lambda\bigg(\sum_{u}{b_{u}^2}+\sum_{u}{b_{i}^2}\bigg)$$

The term ${\frac{1}{N}\sum_{u,i}{\Big(y_{u,i}-\mu -b_{u}-b_{i}\Big)^2}}$ is used to obtain $b_{i}$ and $b_{u}$ and regularized term $\lambda\bigg(\sum_{u}{b_{u}^2}+\sum_{u}{b_{i}^2}\bigg))$ avoids over fitting by penalizing the magnitudes of the parameters.

The regularized term $\lambda\bigg(\sum_{u}{b_{u}^2}+\sum_{u}{b_{i}^2}\bigg)$ avoids over fitting by penalizing the magnitudes of the parameters.

By using a cross-validation the $\hat{b}_{u}$ and $\hat{b}_{i}$ using the adequate $\lambda$ can be found:

$${\hat{b}_{i}(\lambda)=\frac{1}{\lambda + n_{i}}\sum_{u=1}^{n_{i}}{\Big(Y_{u,i}-\hat\mu\Big)^2}}$$

$${\hat{b}_{u}(\lambda)=\frac{1}{\lambda + n_{i}}\sum_{u=1}^{n_{i}}{\Big(Y_{u,i}-\hat\mu-\hat{b}_{i}\Big)^2}}$$

This algorithm generates the following RMSE value: **`r eleventh_model_reg_movie_and_reg_user_effect`**.

### Matrix factorization

Matrix factorization method is used to solve a recommendation system. The idea is to approximate the whole rating matriz $R_{m \times n}$ by the product of two matrics of lower dimensions $P_{k \times m}$ and $Q_{k \times n}$, such that

$$R \approx P'Q$$

The process of solving the matrices **P** and **Q** is referred to as _model training_, and the selection of **penalty** parameters is called _parameter tuning_.

There is an open source library called **recosystem** that can be used using parallel marix factorization (Chin, Yuan, et al. 2015) that have the following steps:

```{r recosystem-steps, warning = FALSE, message = TRUE}
tribble(
  ~"Step", ~"Input", ~"Output",
  "Model training", "Training data set", "-",
  "Parameter tuning","Training data set", "-",
  "Exporting model", "-", "User matrix P, item matrix Q",
  "Prediction", "Testing data set", "Predicted values") %>% 
  kbl(., booktabs = T, caption = "Recosystem steps") %>% kable_styling(latex_options = "HOLD_position") %>% row_spec(0, bold = T)
```

In our case **DataSource** was created using **data_memory()**

The usage of **recosystem** is quite simple, mainly consisting of the following steps:

1. Create a model object (a Reference Class object in R) by calling **Reco()**.
2. (Optionally) call the **tune()** method to select best tuning parameters along a set of candidate values.
3. Train the model by calling the **train()** method. A number of parameters can be set inside the function, possibly coming from the result of **tune()**.
4. (Optionally) export the model via $output(), i.e. write the factorization matrices **P** and **Q** into files or return them as R objects.
5. Use the **predict()** method to compute predicted values.

#### Twelveth model - Matrix factorization

In this model the following data will be used:

* Using **data_memory** for both __train_set__ and __test_set__ datasets:
  + As __user_index__ the predictor __usedId__
  + As __item_index__ the predictor __movieId__
  + As __rating__ the outcome __rating__
* In the __tuning__ parameters only was changed __nthread__ from **1** to **6**, the rest continued the same.
* Using **out_memory** for the predicted values.

The results of 20 iterations are:

```{r twelveth-model, warning = FALSE, message = TRUE}

train_data_recosystem <- with(
  train_set, 
  data_memory(user_index = userId,
              item_index = movieId, 
              rating = rating))

# Create test set using recosystem´s input format
test_data_recosystem <- with(
  test_set,
  data_memory(user_index = userId,
              item_index = movieId, 
              rating = rating))

# Create the model object
matrix_factorization_recosystem <- Reco()

# Use default parameters with exception of nthread from 1 to 6 
opts <- matrix_factorization_recosystem$tune(
  train_data_recosystem, opts = list(dim = c(10L, 20L), 
                                     lrate = c(0.01, 0.1),
                                     costp_l2 = c(0.01, 0.1), 
                                     costq_l2 = c(0.01, 0.1), 
                                     nthread = 6, 
                                     niter = 20))

# Train the algorithm  
matrix_factorization_recosystem$train(
  train_data_recosystem, 
  opts = c(opts$min, nthread = 6, niter = 20))

# Calculate the predicted values  
predictions_matrix_factorization_recosystem <- matrix_factorization_recosystem$predict(test_data_recosystem, out_memory())

# Obtain the RMSE of this model
twelveth_model_matrix_factorization <- RMSE(test_set$rating,predictions_matrix_factorization_recosystem)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(
    Algorithm = "Model #12 - Matrix factorization using recosystem",
    RMSE = twelveth_model_matrix_factorization ))

```

This algorithm generates the following RMSE value: **`r twelveth_model_matrix_factorization`**, being the __lowest__ value obtained.

#### Thirteenth model - Matrix factorization using validation dataset

The following data will be used:

* Using **data_memory** for both __validation__ dataset:
  + As __user_index__ the predictor __usedId__
  + As __item_index__ the predictor __movieId__
  + As __rating__ the outcome __rating__
* Using **out_memory** for the predicted values.

```{r thirteenth-model, warning = FALSE, message = TRUE}

# Create validation set using recosystem´s input format
validation_data_recosystem <- with(
  validation, 
  data_memory(user_index = userId,
              item_index = movieId, 
              rating = rating))

# Calculate the predicted values  
predictions_validation_recosystem <- matrix_factorization_recosystem$predict(validation_data_recosystem, out_memory())

# Obtain the RMSE of this model
thirteenth_model_matrix_factorization_validation_recosystem <- RMSE(validation$rating,predictions_validation_recosystem)

# Append the results to the dataframe
RMSE.results <- bind_rows(
  RMSE.results,
  data_frame(Algorithm = "Model #13 - Matrix factorization using recosystem on validation dataset",
             RMSE = thirteenth_model_matrix_factorization_validation_recosystem ))

```

The RMSE obtained is: **`r thirteenth_model_matrix_factorization_validation_recosystem`**.

### Resume

In the next table are indicated the **RMSEs** obtained on every algorithm being **matrix factorization (best performance)** the one that generated a **`r round(min(RMSE.results$RMSE),5)`** that is below the proposed target.

```{r table-RMSEs, warning = FALSE, message = FALSE}

# Coloring the RMSEs obtained with the minimal value on green color
RMSE.results %>% kbl(., 
      booktabs = T, 
      caption = "RMSEs obtained - Target < 0.86490") %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T) %>% 
  column_spec(
    2, 
    color = "white",
    background = spec_color(
      RMSE.results$RMSE, 
      direction= -1,
      end=0.80),
    popover = paste("RMSE:", RMSE.results$RMSE))
```
The models **#11** and **#12** took **20** and **90 minutes** respectively to run being the ones that could obtain a RMSE below the target.

`\newpage{}`{=latex}'

# Conclusion

The algorithms that took less time to be executed obtained a higher **RMSE** in some cases very similar to the standard deviation and the ones that took more time on being executed obtained a lower **RMSE**.

The results obtained by **factorization model (models #12 and #13)** are **`r  round(100*abs(twelveth_model_matrix_factorization-0.86490)/((twelveth_model_matrix_factorization+0.86490)/2),2)`%** more efficient than the target proposed with the constraint about the computing resources needed to execute the algorithms (for this project a end-user device with **8 GiB RAM**, **2 virtual cores**, **2.90 GHz Intel** processor speed running **Windows 10**). In the other side models such as __user (#2)__, __date effect (#5)__ and __genres (#7)__ had a lower performance by **`r  round(100*abs(second_model_movie_effect-0.86490)/((second_model_movie_effect+0.86490)/2),2)`%**, **`r  round(100*abs(fifth_model_date_effect-0.86490)/((fifth_model_date_effect+0.86490)/2),2)`%**, and **`r  round(100*abs(septh_model_genres_effect-0.86490)/((septh_model_genres_effect+0.86490)/2),2)`%** respectively.

Now based on this experience, the high computing capabilities are needed to generate value as soon as possible, because for the case of a **recommendation system** a strategic decision can be supported based on the results obtained and **cloud computing** can be used with the consideration of the costs involved.

As a future work techniques more advanced such as **neural networks** and **deep learning** can be explored as a way in which an organization will be interested on generate the best customer experience possible in a era of commodities and substitute products using parameters´ relationship where the most important in uncertain times is to increase business value.

`\newpage{}`{=latex}'

# References
* Introduction to Data Science. Rafael A. Irizarry. https://rafalab.github.io/dsbook/
* Create Awesome LaTeX Table with knitr::kable and kableExtra. Hao Zhu. https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
* recosystem: Recommender System Using Parallel Matrix Factorization. Yixuan Qiu. https://cran.r-project.org/web/packages/recosystem/vignettes/introduction.html

[netflix]: https://www.analyticssteps.com/blogs/using-data-handling-and-digital-marketing-maximise-customer-experience-netflix-case-study
[amazon]: https://www.smartinsights.com/digital-marketing-strategy/online-business-revenue-models/amazon-case-study/
[spotify]: https://www.forbes.com/sites/bernardmarr/2017/10/30/the-amazing-ways-spotify-uses-big-data-ai-and-machine-learning-to-drive-business-success/?sh=282254a34bd2
[recommendation_system]: https://en.wikipedia.org/wiki/Recommender_system
[movielens]: https://grouplens.org/datasets/movielens/10m/
[pdf_file]: https://github.com/HugoAquinoNavarrete/MovieLens/blob/main/MovieLens.pdf
[rmd_file]: https://github.com/HugoAquinoNavarrete/MovieLens/blob/main/MovieLens.rmd
[r_file]: https://github.com/HugoAquinoNavarrete/MovieLens/blob/main/MovieLens.R
[github]: https://github.com/HugoAquinoNavarrete/MovieLens
[epoch_format]: https://en.wikipedia.org/wiki/Unix_time